
# The Llama 3 Herd of Models
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21783)
### **论文标题**
- 《Llama 3 驯兽师模型群：支持多语言、编码、推理和工具使用的大型语言模型》

### **作者信息**
- Llama 团队, Meta AI
  - 详细的贡献者名单可以在本文附录中找到。

### **论文标签**
- 大型语言模型、多模态处理、多语言支持、工具使用、代码推理

### **研究核心目标与问题**
- 本研究旨在介绍一组新的基础模型 Llama 3，该模型群能够原生支持多语言、编码、推理和工具使用。研究特别关注于如何通过合成数据生成来增强模型在长文本处理方面的能力。

### **采用方法与技术**
- Llama 3 是基于 Transformer 架构的密集模型，参数量高达 4050 亿，并拥有长达 128K 的上下文窗口。为了提升模型在长文本任务上的表现，研究团队采用了监督微调（SFT）策略，并生成了针对长文本的合成数据。具体来说，使用早期版本的 Llama 3 来生成基于关键长文本用例的合成数据，如问答、文档摘要和代码推理等。
- 在工具使用方面，研究团队创建了包含单步和多步工具使用的合成数据集，以教授模型如何有效地调用外部工具来解决问题。

### **实验设计与主要发现**
- 实验部分展示了 Llama 3 在多项任务中的性能评估，包括语言理解和生成、代码推理以及工具使用等。研究结果显示 Llama 3 在多项任务上的表现与当前领先的模型（如 GPT-4）相当。此外，通过组合的方式将图像、视频和语音能力集成到 Llama 3 中，实验证明这种集成方法在相关任务上也能达到最先进的水平。

### **结论及对未来研究的意义**
- 该研究展示了 Llama 3 在多模态任务处理方面的潜力，并公开发布了包括预训练和后训练版本在内的多个模型。研究还讨论了未来可能的发展方向，包括进一步提高模型的安全性和实用性，以及探索更多模态的集成方式。

### **关键图表与数据**
- 论文中提供了示例图，例如展示了 Llama 3 在涉及多步骤工具使用任务中的表现（图 10），以及模型处理文件上传任务的实例（图 11）。这些图表和数据点对于理解模型在复杂场景下的表现至关重要。
# Tora: Trajectory-oriented Diffusion Transformer for Video Generation
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21705)
### **论文标题**
- **Tora: 基于轨迹导向的扩散变换器进行视频生成**

### **作者信息**
- **Zhenghao Zhang**, **Junchao Liao**, **Menghao Li**, **Long Qin**, **Weizhi Wang**
- **机构**: Alibaba Group

### **论文标签**
- 视频生成
- 扩散模型
- 变换器
- 运动控制

### **研究核心目标与问题**
- 本研究旨在开发一种新的视频生成框架，能够利用文本、图像和轨迹条件来控制视频中的运动。该框架能够生成高质量视频，并保持精确的运动轨迹控制，同时模拟真实世界的物理动态。

### **采用方法与技术**
- 提出了Tora，这是一种基于Diffusion Transformer (DiT) 的视频生成框架，它整合了文本、视觉和轨迹条件。Tora由三个主要组件构成：轨迹提取器（TE）、时空DiT以及运动引导融合器（MGF）。
  - 轨迹提取器使用3D视频压缩网络将任意轨迹编码为时空运动块。
  - 运动引导融合器通过自适应归一化层将运动块集成到DiT模块中，以生成遵循指定轨迹的连贯视频。

### **实验设计与主要发现**
- 实验设计包括两个阶段的训练策略，首先使用密集光流训练模型以加速运动学习，然后通过随机选取不同数量的对象轨迹来微调模型以适应用户友好的稀疏轨迹输入。
- 在多种分辨率（从240p到720p）和帧数（从34帧到204帧）下进行了测试，结果显示Tora在运动保真度方面表现优秀，特别是在长时间序列（例如204帧）的视频生成中，其运动控制稳定性和质量均优于其他方法。

### **结论及对未来研究的意义**
- Tora是第一个轨迹导向的DiT框架，它能够有效处理不同持续时间、宽高比和分辨率的视频，同时保持高精度的运动控制。这一成果为未来的研究提供了强大的基准，尤其是在可控运动的扩散变换器方法领域。

### **关键图表与数据**
- 图5展示了不同分辨率和持续时间下的轨迹误差对比，表明Tora在延长视频时能维持稳定的运动控制。
- 表1列出了与其他运动可控视频生成模型的定量比较结果，显示Tora在增加帧数时具有显著的优势。
- 图6提供了定性比较结果，证明了Tora在运动控制和视觉质量方面的优越性能。
# MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21770)
### 摘要

《MoMa：具有模态意识混合专家的高效早期融合预训练》一文介绍了一种名为MoMa的新颖的模态意识混合专家(MoE)架构，该架构专门用于预训练混合模态、早期融合的语言模型。MoMa通过将图像和文本以任意顺序处理，通过将专家模块分为特定于模态的组来处理图像和文本令牌，从而实现了模态特定参数分配的显著预训练效率提升。实验结果显示，在1万亿个令牌的训练预算下，MoMa 1.4B模型（包含4个文本专家和4个图像专家）在整体上节省了3.7倍的浮点操作（FLOPs），与计算匹配的密集基线相比，文本处理节省了2.6倍，图像处理节省了5.2倍。这优于使用8个多模态专家的标准专家选择的MoE架构，后者整体节省了3倍的FLOPs（文本3倍，图像2.8倍）。结合MoMa与深度混合(MoD)进一步提高了预训练FLOPs节省率至4.2倍（文本：3.4倍，图像：5.3倍），尽管这种组合在因果推理任务中降低了性能，因为路由准确性增加了敏感性。

这些结果证明了MoMa在混合模态、早期融合语言模型预训练效率方面的潜力，为更高效和能力更强的多模态人工智能系统铺平了道路。研究还探讨了在宽度和深度两个维度上应用稀疏架构的有效性，表明每个方向都能实现预训练损失收敛速度的显著提高。然而，如何有效结合这两个方向以在自回归推理设置中获得更好的性能仍然是一个开放的研究挑战。

此外，文中提出了一种模态不耦合的升级技术，进一步增强了稀疏架构的效率。实验提供了广泛的实证结果和分析，揭示了MoMa扩展行为和效率增益的见解。

### 关键词

- 混合模态预训练
- 自回归推理
- 混合专家
- 深度混合
- 模态不耦合升级
# Towards Achieving Human Parity on End-to-end Simultaneous Speech Translation via LLM Agent
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21646)
### **论文标题**
- **标题**: 通过LLM代理实现端到端同声传译的人类水平性能

### **作者信息**
- **作者**: Cross Language Agent Team, ByteDance Research

### **论文标签**
- **主题分类**: 自然语言处理, 机器翻译, 同声传译, 大型语言模型(LLMs)

### **研究核心目标与问题**
- **目标与问题**: 本研究旨在开发一种高质量、接近人类水平的端到端同声传译系统(CLASI)，以解决传统同声传译中的质量与延迟平衡难题，并特别关注专业术语的准确翻译。

### **采用方法与技术**
- **方法与技术**: 
  - 利用新型的数据驱动读写策略来平衡翻译质量和延迟。
  - 针对专业术语的翻译挑战，引入了多模态检索模块以获取相关信息增强翻译质量。
  - 基于大型语言模型(LLMs)，该系统能够容忍错误并综合考虑音频输入、历史上下文和检索到的信息生成翻译。

### **实验设计与主要发现**
- **实验设计**: 
  - 通过实际场景测试评估CLASI系统的表现，这些场景中的讲话往往不流畅、非正式且含糊不清。
  - 使用了一种新的人工评估指标——有效信息比例(VIP)，衡量成功传达给听众的信息量。
- **主要发现**: 
  - 在中文到英文和英文到中文的翻译方向上，CLASI分别实现了81.3%和78.0%的有效信息比例。
  - 相比之下，当前最先进的商用或开源系统仅能分别达到35.4%和41.6%。
  - 即使在极端困难的数据集上，CLASI仍能实现70%的有效信息比例，而其他系统则低于13%。

### **结论及对未来研究的意义**
- **结论**: CLASI系统展示了在同声传译领域的显著进步，特别是在处理复杂和自然对话方面。这表明其在提高同声传译质量方面具有巨大潜力。
- **意义**: 该工作为开发更接近人类水平的同声传译系统奠定了基础，并为未来的自然语言处理研究提供了新的思路和方向。

### **关键图表与数据**
- **图表与数据**: 
  - 实验结果显示，在多种实际应用场景下，CLASI系统相比其他系统在有效信息比例上的表现有显著提升。
  - 提供了详细的比较表格，具体展示了不同系统在不同翻译方向上的表现。
# ShieldGemma: Generative AI Content Moderation Based on Gemma
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21772)
1. **论文标题**  
   - _ShieldGemma: 基于Gemma的生成式AI内容审核_

2. **作者信息**  
   - **ShieldGemma团队**, Google LLC

3. **论文标签**  
   - 大型语言模型(LLM)、内容审核、安全策略、合成数据生成

4. **研究核心目标与问题**  
   - 本研究旨在开发一套全面的内容审核模型系列（ShieldGemma），以检测和过滤大型语言模型(LLM)生成的文本中的有害信息。这些模型基于Gemma2构建，专注于识别性暴露、危险内容、骚扰和仇恨言论等风险类型。通过改进现有解决方案的局限性，如提供更精细的危害类型预测以及适应不同应用场景的需求，本研究旨在提升内容审核的准确性与可靠性。

5. **采用方法与技术**  
   - 研究采用了从2亿到27亿参数不等的多种规模的LLM，以满足不同的部署需求。此外，还提出了一种新的合成数据生成管道，该管道能够产生高质量、多样化的数据集，用于训练模型并提高其对抗攻击的能力。数据集生成过程中利用了指令调优的LLM来创建多样化的、对抗性的输入提示和模型响应。

6. **实验设计与主要发现**  
   - 在公开和内部基准测试上评估了ShieldGemma模型，结果显示它们的表现优于现有的解决方案，例如Llama Guard和WildGuard。在公共基准上，ShieldGemma的平均AU-PRC比Llama Guard高出10.8%，在内部测试数据集上也有显著提升。此外，研究人员还发现，尽管模型大小不同，但9亿和27亿参数的模型在性能上表现相近，略优于2亿参数的模型。

7. **结论及对未来研究的意义**  
   - 本研究为学术界提供了一个有价值的资源，推动了LLM安全领域的进展，并为开发者提供了更有效的内容审核解决方案。通过引入新型的合成数据生成方法，该研究为研究人员和实践者提供了创建高质量、多样化数据集的新工具。未来的研究可以进一步探索如何优化模型的泛化能力，并解决公平性和文化敏感性等问题。

8. **关键图表与数据**  
   - 论文中的图3展示了在内部测试数据集SG Prompt和SG Response上的伤害类型级别的性能（AU-PRC）。所有ShieldGemma模型在所有危害类型上的表现都明显优于GPT-4，这表明ShieldGemma模型在区分不同类型的危害方面具有更强的能力。
# TAROT: Task-Oriented Authorship Obfuscation Using Policy Optimization Methods
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21630)
### **论文标题**
- TAROT: 任务导向型作者身份模糊化使用策略优化方法

### **作者信息**
- Gabriel Loiseau1,2, Damien Sileo2, Damien Riquet1, Maxime Meyer1, Marc Tommasi2
- 1Hornetsecurity, Hem, France
- 2Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189- CRIStAL, F-59000 Lille, France

### **论文标签**
- 作者身份模糊化
- 策略优化
- 隐私保护
- 自然语言处理

### **研究核心目标与问题**
- 本研究旨在解决作者身份模糊化中的隐私与效用之间的权衡问题，即如何在保护作者隐私的同时保持文本的效用。

### **采用方法与技术**
- 提出了TAROT（Task-Oriented Authorship Obfuscation Using Policy Optimization），这是一种新的非监督式作者身份模糊化方法，它利用策略优化来重新生成整个文本以优化隐私与效用之间的权衡。
- 使用了两种策略优化算法：Proximal Policy Optimization (PPO) 和 Direct Preference Optimization (DPO) 来调整小型语言模型，以重写文本同时保留作者身份和下游任务的效用。
- 设计了一个无监督奖励模型，该模型由两个预训练的句子嵌入模型组成，用于评估文本效用和隐私。

### **实验设计与主要发现**
- 实验设计包括使用三种不同的数据集：电影评论、博客文章和学术文档。
- 主要发现是TAROT能够显著降低攻击者识别作者的能力，同时保持较高的文本效用，特别是在使用Direct Preference Optimization时表现更佳。
- 在对抗性攻击场景下，基于生成的方法如TAROT显示出了更强的鲁棒性。

### **结论及对未来研究的意义**
- 结论表明，TAROT能够有效地提高隐私保护水平，同时保持任务效用，这为未来的作者身份模糊化研究提供了一种新的方法路径。
- 对未来的研究意义在于推动开发更加稳健的评价基准，以评估不同场景下的模糊化系统的性能。

### **关键图表与数据**
- 图1展示了TAROT的两个版本：TAROT-PPO 和 TAROT-DPO 的工作流程。
- 表2总结了不同方法在隐私和效用方面的表现，其中TAROT-DPO在IMDB-20数据集上实现了82.46%的隐私保护提升。
- 图2展示了对抗性训练下各方法的表现，其中TAROT-PPO和TAROT-DPO在面对数据增强攻击时具有较好的稳定性。
- 图3展示了使用模糊化文本重新训练效用分类器后的准确性变化，TAROT-PPO和TAROT-DPO在这一指标上的表现最佳。
# Open-Vocabulary Audio-Visual Semantic Segmentation
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21721)
### 论文标题
- 开放词汇音频-视觉语义分割

### 作者信息
- **Ruohao Guo**: 国家通用人工智能重点实验室, 北京大学智能科学与技术学院, 北京, 中国
- **Liao Qu**: 卡内基梅隆大学电气与计算机工程系, 匹兹堡, PA, 美国
- **Dantong Niu**: 加州大学伯克利分校伯克利人工智能研究所, 伯克利, CA, 美国
- **Yanyu Qi**: 中国农业大学信息与电气工程学院, 北京, 中国
- **Wenzhen Yue**: 国家通用人工智能重点实验室, 北京大学智能科学与技术学院, 北京, 中国
- **Ji Shi**: 国家通用人工智能重点实验室, 北京大学智能科学与技术学院, 北京, 中国
- **Bowei Xing**: 国家通用人工智能重点实验室, 北京大学智能科学与技术学院, 北京, 中国
- **Xianghua Ying** (通讯作者): 国家通用人工智能重点实验室, 北京大学智能科学与技术学院, 北京, 中国

### 论文标签
- 视频分割
- 开放词汇学习
- 音频-视觉语义分割
- 视觉语言模型
- Transformer
- 多模态融合

### 研究核心目标与问题
- 本文提出了一种新的任务——开放词汇音频-视觉语义分割（OV-AVSS），旨在扩展传统的音频-视觉语义分割（AVSS）任务，使其能够处理开放世界场景中的未标注类别。该任务要求模型不仅能识别训练数据中预定义的类别，还能检测出现在实际应用场景中的新类别。

### 采用方法与技术
- 提出了一个开放词汇AVSS框架（OV-AVSS），主要包括两个部分：
  - 通用声源定位模块（USSLM），用于进行音频-视觉融合并定位所有潜在的发声物体；
  - 开放词汇分类模块（OVCM），利用大规模预训练视觉语言模型的帮助预测类别。

### 实验设计与主要发现
- 设计了开放词汇音频-视觉语义分割评估基准AVSBench-OV，该基准基于AVSBench-semantic数据集划分零样本训练和测试子集。
- 在AVSBench-OV数据集上进行了广泛实验，验证了模型在所有类别上的强大分割能力和零样本泛化能力。具体来说，在基础类别上实现了55.43%的平均交并比（mIoU），在新颖类别上达到了29.14%的mIoU，分别超越了最先进的零样本方法41.88%和20.61%，以及开放词汇方法10.2%和11.6%。

### 结论及对未来研究的意义
- 本研究提出了一个新的多模态任务——开放词汇音频-视觉语义分割，并开发了一个强大的基线模型。实验结果表明，该模型在性能和泛化能力方面达到了最先进的水平，为开放词汇环境下的音频-视觉分割提供了重要的参考和支持。

### 关键图表与数据
- 图4展示了定性结果，证明了模型在不同类别（包括新颖类别）上的精确分割能力。
- 表1和表2比较了所提出的模型与其他方法在不同指标上的性能，显示了其显著优势。
# Data Contamination Report from the 2024 CONDA Shared Task
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21530)
### **论文标题**
- 数据污染报告：2024年CONDA共享任务

### **作者信息**
- **作者**：Oscar Sainz, Iker García-Ferrero, Alon Jacovi, Jon Ander Campos, Yanai Elazar, Eneko Agirre, Yoav Goldberg, Wei-Lin Chen, Jenny Chim, Leshem Choshen, Luca D’Amico-Wong, Melissa Dell, Run-Ze Fan, Shahriar Golchin, Yucheng Li, Pengfei Liu, Bhavish Pahwa, Ameya Prabhu, Suryansh Sharma, Emily Silcock, Kateryna Solonko, David Stap, Mihai Surdeanu, Yu-Min Tseng, Vishaal Udandarao, Zengzhi Wang, Ruijie Xu, Jinglin Yang
- **机构**：来自HiTZ中心、巴伊兰大学、Cohere、艾伦人工智能研究所、华盛顿大学、国立台湾大学、弗吉尼亚大学、伦敦玛丽女王大学、MIT-IBM沃森AI实验室、哈佛大学、上海交通大学、亚利桑那大学、萨里大学、微软研究院、图宾根AI中心、印度理工学院卡哈格布尔分校、阿姆斯特丹大学、微软公司和剑桥大学等多个机构。

### **论文标签**
- 自然语言处理（NLP）、数据污染、模型评估、资源共享

### **研究核心目标与问题**
- 本研究关注自然语言处理领域的数据污染问题，特别是在大规模预训练模型的评估数据被包含在其训练语料中的情况。这会导致评估结果的偏差或误导性。通过2024年的CONDA共享任务，研究旨在收集当前可用数据集和模型中的污染证据，以帮助社区更好地理解该问题的严重性和范围，并指导研究人员避免使用已知受污染的数据资源进行评估。

### **采用方法与技术**
- 为了实现这一目标，研究团队开发了一个结构化的公共数据库，用于集中收集和记录数据污染的相关证据。该数据库通过GitHub上的合并请求机制对外开放，鼓励社区成员贡献新的发现。此外，研究者们还分析了多种现有的数据集和模型，以识别其中可能存在的污染问题。

### **实验设计与主要发现**
- 实验设计基于社区提交的数据污染案例，这些案例涉及多个不同的数据集和模型。通过系统地收集和验证这些案例，研究者们能够构建起一个全面的数据库，其中包括了566个报告的条目，详细记录了不同场景下的数据污染情况。

### **结论及对未来研究的意义**
- 该研究为自然语言处理领域的数据污染问题提供了首个系统性的分析和解决方案，强调了建立一个开放、共享的数据库对于理解和解决该问题的重要性。它不仅有助于提高模型评估的准确性，也为未来的相关研究奠定了基础。

### **关键图表与数据**
- 研究中提到了一个包含566个报告条目的数据库，这些条目详细记录了数据污染的情况，是理解研究结果的关键。
# Improving 2D Feature Representations by 3D-Aware Fine-Tuning
[arxiv_pdf_url](https://arxiv.org/pdf/2407.20229)
### **论文标题**
- 改进2D特征表示：通过3D感知微调

### **作者信息**
- Yuanwen Yue, Anurag Das, Francis Engelmann, Siyu Tang, Jan Eric Lenssen
- 机构：ETH Zurich, Max Planck Institute for Informatics, Saarland Informatics Campus, Google

### **论文标签**
- 表示学习, 基础模型, 高斯散射, 场景理解

### **研究核心目标与问题**
- 当前视觉基础模型仅基于无结构的2D数据训练，限制了其对物体和场景三维结构的理解能力。本文旨在通过3D感知数据上的微调来改进2D基础特征的质量，以增强模型对3D结构的理解。

### **采用方法与技术**
- 设计了一种将2D语义特征提升到高效3D高斯表示的方法，该表示允许从任意视角重新渲染特征。
- 利用重渲染后的3D感知特征，设计了一种微调策略，将3D感知信息转移到2D基础模型中。

### **实验设计与主要发现**
- 实验中首先将多视角2D基础特征提升至3D高斯表示，然后使用这些表示进行微调。
- 微调后，通过简单的线性探测评估下游任务（如语义分割和深度估计）的表现。
- 结果显示，在多个数据集上，通过3D感知微调改进的特征显著提高了下游任务的性能。

### **结论及对未来研究的意义**
- 研究表明，通过3D感知微调得到的特征可以有效改善2D基础模型在语义和几何任务上的表现。
- 尽管仅在一个室内数据集上进行了3D感知微调，但改进的效果可以迁移到多种室内数据集以及跨领域的数据集上。
- 本工作鼓励社区考虑在训练2D基础模型时注入3D感知理解。

### **关键图表与数据**
- 图1展示了将2D特征提升为3D表示的过程，并利用3D感知特征进行微调。
- 图2展示了不同2D视觉模型通过3D感知微调后的性能提升。
- 表1和表2分别提供了在室内数据集上进行语义分割和深度估计任务的结果，证明了方法的有效性。
- 表3展示了在域外数据集上性能的提升情况，证明了方法的泛化能力。
# Berkeley Humanoid: A Research Platform for Learning-based Control
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21781)
### **论文标题**
伯克利人形机器人：面向基于学习的控制的研究平台

### **作者信息**
- Qiayuan Liao, Bike Zhang, Xuanyu Huang, Xiaoyu Huang, Zhongyu Li, Koushil Sreenath
- 作者单位：加州大学伯克利分校

### **论文标签**
- 人形机器人
- 硬件设计
- 强化学习

### **研究核心目标与问题**
本研究旨在开发一种可靠且低成本的中型人形机器人平台，特别针对基于学习的控制策略进行优化。该平台旨在通过缩小模拟与现实之间的差距来实现动态运动控制，并能在各种户外环境中稳健行走。

### **采用方法与技术**
- 开发了一种自定义的中型人形机器人，具有轻量化、紧凑的设计，适用于基于学习的控制算法。
- 使用了集成式传动装置和空心轴的定制模块化执行器以实现高扭矩密度。
- 采用EtherCAT通信协议保证低延迟、高带宽的通信。
- 设计上考虑了仿真友好性、可靠性、低成本以及类人特性。

### **实验设计与主要发现**
- 实验展示了机器人在不同地形上的全向行走能力，包括草地、砖道、不平坦路面等。
- 机器人能够稳定地爬升陡峭且狭窄的未经铺设的小径。
- 在受到外部扰动时（如被踢），机器人能够快速恢复平衡并继续行走。
- 长距离测试表明机器人能够在校园内连续行走超过10分钟，覆盖364米的距离，包括上下坡。
- 使用简单的强化学习控制器实现了单腿和双腿跳跃的能力。

### **结论及对未来研究的意义**
本文介绍了一种可靠且低成本的人形机器人平台，其专为基于学习的控制策略而设计。该平台能够实现在复杂地形上的动态运动控制，展示了小模拟到现实差距的优势。此外，该平台还证明了其硬件的耐用性和可靠性。这项工作为未来的机器人研究提供了新的可能性，特别是在学习控制领域的规模化部署方面。

### **关键图表与数据**
- 图4展示了机器人在实验室环境中的全向行走能力。
- 图5和图6展示了机器人在不同地形上的行走能力和对外部扰动的应对能力。
- 图7记录了机器人长距离行走的GPS轨迹。
- 图8评估了模拟与现实之间的转移性能。
- 图9展示了机器人跳跃的能力。
# Expressive Whole-Body 3D Gaussian Avatar
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21686)
### **论文标题**
- 表达式全身3D高斯Avatar

### **作者信息**
- Gyeongsik Moon<sup>1,2</sup>, Takaaki Shiratori<sup>2</sup>, 和 Shunsuke Saito<sup>2</sup>
- <sup>1</sup>DGIST, <sup>2</sup>Codec Avatars Lab, Meta

### **论文标签**
- 计算机视觉, 3D重建, 人体建模, 高斯体素, Avatar生成

### **研究核心目标与问题**
- 本文提出了一种新的全身3D Avatar（ExAvatar）建模方法，该Avatar能够从简短的单目视频中学习获得，支持面部表情和手部动作。研究解决了视频中面部表情和姿势多样性有限以及缺乏3D观测数据（如3D扫描或RGBD图像）的问题。

### **采用方法与技术**
- ExAvatar结合了全身参数化网格模型（SMPL-X）和3D高斯体素（3DGS），利用混合表示法将每个3D高斯体素视为网格表面上的一个顶点，拥有预定义的连接信息（三角形面）。这种方法使得Avatar可以被驱动以产生新颖的面部表情，并通过使用基于连接性的正则化器显著减少新型面部表情和姿势下的伪影。

### **实验设计与主要发现**
- 实验采用了两个数据集：NeuMan和X-Humans。NeuMan数据集包含来自真实环境的短单目视频；X-Humans数据集提供多样化的面部表情和手部姿势，但ExAvatar仅使用单目RGB视频。研究结果显示，ExAvatar在各种基准测试中显著优于现有3D Avatar，在新视角和姿势下的渲染更为逼真，特别是在面部和手部细节方面表现更佳。

### **结论及对未来研究的意义**
- ExAvatar成功地解决了视频中面部表情和姿势多样性有限的问题，并且无需3D观测数据即可实现高质量的Avatar生成。这项工作为创建实用且高度表达性的3D Avatar开辟了新途径，尤其适用于日常生活中常见的短单目视频。未来的研究可考虑如何更好地模拟未观察到的人体部分，例如口腔内部和手掌。

### **关键图表与数据**
- 图1展示了从单人单目视频到表达式全身3D Avatar的过程。
- 图2和图3验证了关节偏移和面部偏移对于精确注册手部和面部的重要性。
- 表1和表2显示ExAvatar在NeuMan数据集上的性能优于其他方法。
- 表3表明即使没有深度图，ExAvatar在X-Humans数据集上也超过了之前的工作。
# Fine-gained Zero-shot Video Sampling
[arxiv_pdf_url](https://arxiv.org/pdf/2407.21475)
### **论文标题**
- 细粒度零样本视频采样

### **作者信息**
- **Dengsheng Chen**, **Jie Hu**, **Xiaoming Wei**, Meituan
- **Enhua Wu**, SKLCS, Institute of Software, Chinese Academy of Sciences

### **论文标签**
- 计算机视觉 | 视频生成 | 零样本学习 | 扩散模型

### **研究核心目标与问题**
- 本研究旨在解决现有视频生成方法中存在的计算成本高昂和训练所需大规模视频数据集的问题。特别关注的是如何避免图像和视频数据集之间的差异导致的“灾难性遗忘”。提出了一种名为ZS²的新颖零样本视频采样算法，能够在无需额外训练的情况下直接从预训练的图像扩散模型中生成高质量视频片段。

### **采用方法与技术**
- ZS²算法结合了依赖噪声模型和时间动量注意力机制，前者用于确保内容一致性，后者则保证动画连贯性。通过这些技术，算法能够直接从诸如Stable Diffusion这样的图像合成方法中采样视频片段，而无需任何训练或优化过程。

### **实验设计与主要发现**
- 实验设计采用了多个不同的图像扩散模型进行测试，包括Stable Diffusion的不同版本、Dreamlike Photoreal的不同版本以及Openjourney。通过对生成视频的质量评估，特别是使用CLIP分数这一量化指标，验证了ZS²算法的有效性和优越性。结果显示，在零样本视频生成任务上，ZS²达到了最先进的性能，并在某些情况下超越了近期的监督学习方法。

### **结论及对未来研究的意义**
- 本文提出了ZS²算法，这是一种创新的零样本视频采样方法，它能够直接从预训练的图像扩散模型中高效生成高质量的视频片段。该方法不仅显著降低了视频生成的成本，还展示了在条件视频生成、特定场景视频生成以及基于文本指令的视频编辑等多个领域的应用潜力。这项工作为未来的视频生成研究提供了新的思路和技术基础。

### **关键图表与数据**
- 文章中提到了几个关键图表，包括图1展示的方法能够生成更细致、语义更丰富的运动变化；图2展示了不同图像扩散模型下的方法表现；图3对比了ZS²与基线方法Text2Video-Zero的效果；图4展示了通过调节参数λi和µi可以有效控制视频内容的变化；表1列出了不同采样方法与不同扩散模型组合时的CLIP分数，证明了ZS²算法的优越性和泛化能力。
# NeRF-MAE: Masked AutoEncoders for Self-Supervised 3D Representation Learning for Neural Radiance Fields
[arxiv_pdf_url](https://arxiv.org/pdf/2404.01300)
### **论文标题**
- 论文标题：NeRF-MAE: 自监督预训练用于神经辐射场的3D表示学习

### **作者信息**
- 作者：Muhammad Zubair Irshad, Sergey Zakharov, Vitor Guizilini, Adrien Gaidon, Zsolt Kira, Rares Ambrus
- 机构：Toyota Research Institute, Georgia Tech

### **论文标签**
- 主题分类：计算机视觉、机器人学、自监督学习、3D表示学习、神经辐射场（NeRF）

### **研究核心目标与问题**
- 本研究旨在通过使用掩码自编码器（masked autoencoders）扩展神经辐射场（NeRF）的自监督预训练，以生成有效的3D表示。研究探讨了如何利用NeRF的辐射和密度网格作为输入模态进行大规模自监督预训练的可能性。

### **采用方法与技术**
- 研究使用标准Transformer架构来学习从定位RGB图像中提取的强大3D表示。具体而言，研究采用了以下步骤：
  - 从完全训练好的隐式NeRF模型中使用相机轨迹感知采样提取明确的4D辐射和密度网格。
  - 使用一个基于密度的掩码自监督预训练模块直接作用于NeRF的4D辐射和密度网格上，训练标准3D SwinTransformer编码器和体素解码器。
  - 通过一个考虑不透明度的掩码重建目标进行3D重建。

### **实验设计与主要发现**
- 实验设计包括在多个基准数据集上的下游任务评估，如3D物体检测、超分辨率和体素标记。研究团队利用Front3D和ScanNet数据集进行了测试。
- 主要发现：
  - 在3D物体检测任务上，NeRF-MAE在Front3D数据集上实现了63%的AP50和74.3%的Recall50，在ScanNet数据集上达到了17%的AP50和39.5%的Recall50。
  - 在语义体素标记任务上，NeRF-MAE实现了81%的准确性、45%的平均准确性(mAcc)和34.5%的平均交并比(mIOU)，相比NeRF-RPN提高了6.8%的准确性、12.9%的mAcc和9.8%的mIOU。
  - 在体素超分辨率任务上，NeRF-MAE表现出更高的3D PSNR和更低的MSE指标。

### **结论及对未来研究的意义**
- 结论表明，NeRF-MAE能够通过利用密集体积NeRF网格和考虑不透明度的重建目标来学习更好的表示。这为未来的3D表示学习和下游任务提供了新的方向。

### **关键图表与数据**
- 图1概述了NeRF-MAE的方法论，展示了掩码预训练阶段以及下游3D任务的执行过程。
- 表5量化地比较了NeRF-MAE与NeRF-RPN在体素语义标记和超分辨率任务上的性能。
- 图8展示了NeRF-MAE在体素标记任务上的定性结果。
- 图9展示了NeRF-MAE在3D边界框预测任务上的定性结果。