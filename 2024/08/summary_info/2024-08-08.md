
# Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03615)
### **论文标题**
- 一种基于混合多模态记忆的智能体：Optimus-1 在长周期任务中的卓越表现

### **作者信息**
- 李再静$^{1,2}$, 谢宇权$^1$, 邵锐$^{1*}$, 陈功卫$^1$, 姜东梅$^2$, 聂立强$^{1*}$
- $^1$哈尔滨工业大学（深圳） $^2$鹏城实验室
- $\{$lzj14011,xieyuquan20016,rshaojimmy,nieliqiang$\}@gmail.com$

### **论文标签**
- 人工智能、长周期任务、多模态记忆、混合记忆模块、强化学习

### **研究核心目标与问题**
- 本研究旨在构建一种通用智能体，以解决开放世界中的长周期任务。当前的智能体虽然在多个领域取得了显著进步，但在完成长周期任务时仍然面临挑战。研究指出，这主要是因为缺乏必要的世界知识和多模态经验来指导智能体应对各种复杂的长周期任务。

### **采用方法与技术**
- 提出了一个混合多模态记忆模块（Hybrid Multimodal Memory），该模块能够将知识转换为层次化有向知识图谱（Hierarchical Directed Knowledge Graph），使智能体能够显式表示并学习世界知识。同时，该模块还能够汇总历史信息为抽象化的多模态经验池（Abstracted Multimodal Experience Pool）。

### **实验设计与主要发现**
- 实验在Minecraft环境中进行，设计了一系列长周期任务，例如制作石剑。实验中，智能体通过知识引导规划器（Knowledge-Guided Planner）结合层次化有向知识图谱中的知识进行规划，然后通过行动控制器（Action Controller）执行这些规划序列。在执行过程中，经验驱动反射器（Experience-Driven Reflector）会定期激活，从抽象化的多模态经验池中检索经验进行反思。
- 主要发现包括：混合多模态记忆模块能够帮助智能体更好地利用结构化知识和多模态经验，从而在长周期任务上取得更佳表现。

### **结论及对未来研究的意义**
- 通过引入混合多模态记忆模块，智能体能够在复杂环境中完成一系列长周期任务，这为构建能够处理现实世界中复杂场景的通用智能体提供了新的思路。未来的研究可以进一步探索如何扩展智能体的能力，使其能够适应更多样化的任务和环境。

### **关键图表与数据**
- 图1展示了Optimus-1在Minecraft环境中完成“制作石剑”这一长周期任务的过程。图中详细描绘了从规划到执行的整个流程，以及在执行过程中的反思机制。
# EXAONE 3.0 7.8B Instruction Tuned Language Model
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03541)
### EXAONE 3.0 7.8B 指令调谐语言模型概述

#### 论文标题翻译：
《EXAONE 3.0 7.8B 指令调谐语言模型》

#### 作者信息：
- LG AI Research 的多位贡献者，名单在第8节“贡献者”部分列出。

#### 标签：
- 大型语言模型（Large Language Models, LLMs）
- 指令调谐（Instruction-tuned）
- LG AI Research 开发
- 韩语能力突出
- 英语性能竞争
- 多语言支持

#### 研究核心目标与问题：
- 介绍 LG AI Research 开发的 EXAONE 3.0 7.8B 指令调谐语言模型，这是大型语言模型家族中首个公开发布的模型，旨在促进开放研究和创新。
- 解决大型语言模型在不同任务上性能差异、特定语言（如韩语）表现优化的问题，以及如何提高模型在真实世界场景中的实用性。

#### 采用方法与技术：
- **模型训练**：基于解码器的变压器架构，最大上下文长度为 4096 个令牌，使用了旋转位置嵌入（RoPE）和分组查询注意力（GQA）等技术。
- **分词器设计**：双语言（英语和韩语）支持，针对韩语的粘着性特征进行了预处理。
- **预训练**：使用超大规模数据集进行预训练，包括大量网络爬虫数据，通过数据清洗和质量控制策略来提升数据质量和多样性。
- **后训练**：包括监督微调（SFT）和直接偏好优化（DPO），以增强模型的指令遵循能力。

#### 实验设计与主要发现：
- 在英语和韩语上进行了广泛评估，结果显示该模型在性能上具有竞争力，并且在某些任务上表现出色，特别是韩语任务。
- 主要发现包括在多个基准测试中的平均性能排名，特别是在韩国本地基准测试中表现出色。

#### 结论及对未来研究的意义：
- EXAONE 3.0 7.8B 模型展示了在真实世界场景中与同类模型相媲美的性能，特别是在韩语任务上表现出色。
- 对于未来研究，模型的发布旨在促进跨领域的合作和创新，尤其是在专家级人工智能领域。

#### 关键图表与数据：
- 包括但不限于基准测试结果的表格、性能比较图表以及评估方法的详细描述。

#### 总结：
《EXAONE 3.0 7.8B 指令调谐语言模型》是 LG AI Research 发布的首个公开的大型语言模型，特别强调了在韩语上的能力，并在英语和其他语言任务上也展现出竞争力。通过详细的模型训练、评估方法和性能比较，论文提供了对该模型在真实世界应用中的潜力和价值的深入洞察。
# Achieving Human Level Competitive Robot Table Tennis
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03906)
### **论文标题**
- 实现人类水平竞技的机器人乒乓球

### **作者信息**
- **主要贡献者**: David B. D’Ambrosio, Saminda Abeyruwan, Laura Graesser, Atil Iscen, Grace Vesom, Peng Xu, Pannag R. Sanketi (Google DeepMind)
- **核心贡献者**: Heni Ben Amor, Alex Bewley, Barney J. Reed, Krista Reymann, Leila Takayama, Yuval Tassa, Krzysztof Choromanski, Erwin Coumans, Deepali Jain, Navdeep Jaitly, Natasha Jaques, Satoshi Kataoka, Yuheng Kuang, Nevena Lazic, Reza Mahjourian, Sherry Moore, Kenneth Oslund, Anish Shankar, Vikas Sindhwani, Vincent Vanhoucke
- **通讯作者**: David B. D’Ambrosio, Saminda Abeyruwan, Laura Graesser (Google DeepMind)

### **论文标签**
- 机器人技术
- 强化学习
- 运动控制
- 体育竞技
- 乒乓球

### **研究核心目标与问题**
- 本研究的目标是开发一个能够达到业余人类水平的机器人乒乓球代理。通过解决这一挑战，研究团队旨在缩小模拟环境与现实世界任务之间的差距，以实现机器人的高级物理技能。

### **采用方法与技术**
- 提出了一个层次化和模块化的策略架构，包括：
  - 低级别控制器：负责执行具体的乒乓球技能，如击球技巧。
  - 高级别控制器：根据当前比赛状态选择合适的低级别技能。
- 使用了零样本模拟到真实世界的迁移技术来优化技能选择策略。

### **实验设计与主要发现**
- 该研究通过与不同水平的人类对手进行比赛测试了机器人的性能。
- 机器人能够成功地与人类玩家竞争，并且根据对手的不同技能水平调整其策略。
- 关键发现表明，机器人的表现随着对手技能水平的提高而有所提升，证明了所提出架构的有效性。

### **结论及对未来研究的意义**
- 本文展示了机器人在一项复杂的体育竞技项目上达到了业余人类水平的能力。
- 这项工作为未来的机器人研究提供了有价值的见解，尤其是在如何将模拟训练迁移到实际环境中，以及如何设计灵活的多层次控制策略方面。

### **关键图表与数据**
- 图1展示了机器人与一位专业教练进行比赛的场景，通过绿色轨迹点表示球的运动路径。
- 表V和表VI提供了MuJoCo模拟器参数的详细配置，用于实现逼真的物理交互。
- 图15给出了使用预评估技能级别的比赛统计，尽管这些数据不影响主要结果，但有助于验证技能评估过程的准确性。
# WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03837)
### **论文标题**
- WALLEDEVAL: 一种全面的安全评估工具包，用于大型语言模型的安全性测试

### **作者信息**
- Prannaya Gupta*, Le Qi Yau*, Hao Han Low*, I-Shiang Lee*, Hugo M. Lim*, Yu Xin Teoh*, Jia Hng Koh*, Dar Win Liew†, Rishabh Bhardwaj‡, Rajat Bhardwaj‡, Soujanya Poria‡
- *独立研究者, †来自Tensorplex Labs的合作者, ‡主要贡献者, 电子邮箱: rishabh@walled.ai
- 机构: Walled AI Labs

### **论文标签**
- 大型语言模型(LLMs)
- 安全评估
- 工具包
- 人工智能安全
- 互文安全性

### **研究核心目标与问题**
- 本研究旨在开发一个名为WALLEDEVAL的综合性AI安全测试工具包，用于评估大型语言模型(LLMs)的安全性风险。
- 随着越来越多的大型语言模型出现，它们在知识和多任务处理能力方面的增强带来了对全面安全评估的迫切需求。

### **采用方法与技术**
- WALLEDEVAL支持开放权重和API基模型，并提供了超过35个安全基准测试，涵盖了多语言安全、互文安全性和提示注入等多个方面。
- 包括了自定义变异器(mutators)，可以进行多种文本风格变异测试，例如将来时态和释义。
- 引入了WALLEDGUARD，一款新的、小型且高效的内容审核工具，以及SGXSTEST，一个评估特定文化背景下的互文安全性的基准测试。

### **实验设计与主要发现**
- 实验设计框架包括模型加载、数据集准备、安全评估等步骤。
- 在实验中，研究团队测试了不同模型（如Llamas、Mistrals等）在有害行为和拒绝行为上的表现。
- 发现了模型在面对变异提示时的行为差异，并观察到某些模型在文化特异性提示上表现出过度拒绝行为。
- 使用了多种评估指标，包括有害分数和拒绝分数，来量化模型的安全性能。

### **结论及对未来研究的意义**
- WALLEDEVAL为评估大型语言模型的安全性提供了一个全面的解决方案，并引入了一些新的评估工具和数据集。
- 对于未来的研究，该工具包能够促进更深入地理解模型的安全边界，并有助于开发更有效的安全措施。

### **关键图表与数据**
- 表1展示了不同模型在有害行为和拒绝行为测试中的得分情况。
- 表2比较了不同内容审核器在多语言和互文安全数据集上的性能。
- 表3列出了多个模型在多语言安全测试中的表现。
# CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03910)
### 论文标题
- CODEXGRAPH: 通过代码图数据库连接大型语言模型与代码仓库

### 作者信息
- 刘翔燕1,2,∗ 兰波3,∗ 胡智远1 刘洋2 张志成2 周文萌2 王菲3 郭迈克1
- 1 新加坡国立大学 2 阿里巴巴集团 3 西安交通大学

### 论文标签
- 大型语言模型
- 代码仓库
- 图数据库
- 代码检索
- 自动化软件工程

### 研究核心目标与问题
- 当前大型语言模型（LLMs）在处理独立代码任务时表现出色，但在处理整个代码仓库时面临挑战。研究旨在通过利用代码图数据库增强LLMs与代码仓库之间的交互，解决复杂任务中的代码检索和理解问题。

### 采用方法与技术
- 提出了CODEXGRAPH系统，该系统通过静态分析从代码仓库中提取代码图，并使用统一的图数据库模式存储这些图。LLM代理能够构建和执行基于图查询语言的查询，以精确地检索代码结构相关的信息并导航代码仓库。
- 实现了多阶段索引过程，包括浅层索引和完整边关系构建，以确保高效且全面地捕捉代码符号和关系。
- 设计了主LLM代理与翻译LLM代理相结合的策略，以优化查询生成和执行过程，提高查询成功率。

### 实验设计与主要发现
- 评估了CODEXGRAPH在三个基准测试集上的性能：CrossCodeEval、SWE-bench 和 EvoCodeBench，涵盖了代码补全、GitHub问题解决和代码生成等多种任务。
- 实验结果显示，CODEXGRAPH在所有基准测试上均表现出竞争力，特别是在配备更先进的LLMs时，如GPT-4o。此外，与传统的基于相似性的检索和手动工具相比，CODEXGRAPH提供了更灵活和通用的接口，适用于多种代码任务。

### 结论及对未来研究的意义
- CODEXGRAPH展示了在学术和实际环境中处理复杂代码任务的强大潜力，特别是在代码理解和导航方面。其设计为软件工程领域的自动化工具开发提供了一个有力的解决方案，并有望推动未来研究的发展。

### 关键图表与数据
- 表1比较了CODEXGRAPH与其他基线方法在不同基准测试上的性能，表明CODEXGRAPH在多个评价指标上取得了显著提升。
- 图3展示了主LLM代理如何生成自然语言查询，以及翻译LLM代理如何将这些查询转换为可执行的图查询的过程。
- 图4比较了不同查询策略的效果，显示了在不同基准测试上单个查询与多个查询策略的表现差异。
# Openstory++: A Large-scale Dataset and Benchmark for Instance-aware Open-domain Visual Storytelling
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03695)
### **论文标题**
- Openstory++: 大规模数据集及基准测试用于实例感知的开放域视觉叙事生成

### **作者信息**
- **作者**: Zilyu Ye, Jinxiu Liu, Ruotian Peng, JinJin Cao, Zhiyang Chen, Yiyang Zhang, Ziwei Xuan, Mingyuan Zhou, Xiaoqian Shen, Mohamed Elhoseiny, Qi Liu, Guo-Jun Qi
- **机构**: 华南理工大学, 西湖大学, OPPO美国研发中心, 中科院模式识别国家重点实验室, 阿卜杜拉国王科技大学

### **论文标签**
- 视觉叙事生成, 多模态学习, 数据集, 基准测试, 实例感知

### **研究核心目标与问题**
- 本研究旨在解决当前图像生成模型在处理长文本上下文时无法保持多实例一致性的问题。特别是针对开放域视觉叙事生成任务，研究者们面临着训练数据集中缺乏细粒度实例特征标记的问题。

### **采用方法与技术**
- 开发了Openstory++数据集，该数据集包含额外的实例级标注，同时结合图像和文本。
- 设计了一种定制化的训练方法，强调实体为中心的图像-文本生成，确保模型能有效地融合视觉和文本信息。
- 利用视频内容提取关键帧，使用视觉语言模型生成描述性标题，并通过大型语言模型进行优化以保证叙述连贯性。
- 创建了一个自动化的工作流程来识别图像中的有效实例，并为这些实例创建掩码。
- 开发了Cohere-Bench，这是一个开创性的基准框架，用于评估在提供长多模态上下文时的图像生成任务。

### **实验设计与主要发现**
- 在Cohere-Bench框架下进行的实验验证了Openstory++在培养高质量视觉叙事生成模型方面的优越性。
- 该数据集显著提高了模型处理复杂和开放域生成任务的能力，特别是在维持背景、风格和实例连贯性方面。
- 实验还表明，通过使用实例级标注可以显著提高模型的性能。

### **结论及对未来研究的意义**
- 本研究通过引入Openstory++数据集和Cohere-Bench基准框架，为多模态生成领域的研究提供了重要进展。
- 这些贡献不仅增强了现有模型的能力，也为未来在开放域环境中生成和解释复杂叙事的研究开辟了道路。

### **关键图表与数据**
- 图1展示了数据集的可视化，其中左侧是一个带有视觉注释的数据案例，右侧是数据集注释过程的一般流程。
- 表1对比了Openstory++与其他视觉叙事数据集的关键统计数据，显示其在序列长度、实例连续性和数据量等方面的优越性。
- 表2比较了不同数据集上模型的多项指标，如语义对齐、风格一致性、实例一致性等，证明了Openstory++数据集的有效性。
- 表3列出了多个模型在Cohere-Bench上的定量评估结果，突出了本文提出的方法在单实例和多实例设置下的优势。
# RayGauss: Volumetric Gaussian-Based Ray Casting for Photorealistic Novel View Synthesis
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03356)
### **论文标题**
- **RayGauss: 基于体素高斯分布的光线投射法用于逼真新视图合成**

### **作者信息**
- **Hugo Blanc**, **Jean-Emmanuel Deschaud**, **Alexis Paljic**
  - 机构：MINES Paris-PSL, 法国

### **论文标签**
- **计算机视觉**、**深度学习**、**光线追踪**、**新型视图合成**、**高斯核**

### **研究核心目标与问题**
- 该研究致力于改进基于体积渲染的新视图合成技术，以提高渲染质量和效率。研究的核心问题在于如何结合高斯分布的优势和光线投射法的精确性来实现快速而高质量的新视图合成。

### **采用方法与技术**
- 本研究提出了一种新的光线投射算法RayGauss，它使用分解为高斯函数的辐射强度\(c\)和密度\(\sigma\)，并结合球面高斯/谐波表示全频色彩信息。此外，该方法还引入了一个能够对不规则分布的高斯函数进行可微分光线投射的算法，通过逐层积分辐射场和利用BVH结构来避免splatting过程中的明显伪影。

### **实验设计与主要发现**
- 实验部分详细介绍了优化参数设置，如学习率、参数解锁策略以及自适应高斯控制等。研究使用了Blender和Mip-NeRF360数据集进行评估，结果显示RayGauss在保持合理训练时间的同时，达到了25FPS的推理速度，显著提高了渲染质量。

### **结论及对未来研究的意义**
- RayGauss成功地实现了比现有技术更高质量的渲染效果，同时保持了合理的训练时间和高效的推理速度。这一成果为未来的研究提供了新的方向，特别是对于需要高效且高质量视图合成的应用场景。

### **关键图表与数据**
- 表格数据显示了RayGauss与现有方法（如Gaussian Splatting）在Blender和Mip-NeRF360数据集上的性能比较。其中，RayGauss在训练时间和推理速度上表现出色，同时在PSNR和SSIM指标上也取得了显著的提升。
# Fast Sprite Decomposition from Animated Graphics
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03923)
### 快速精灵分解从动画图形

#### 摘要

本文提出了一种从动画图形中分解精灵（基本元素或图层集）的方法。该方法基于优化精灵参数以适应矢量视频的过程。为了提高效率，假设精灵具有静态纹理，同时使用纹理先验模型防止不希望的像素艺术效果。通过引入初始化步骤，利用预训练的视频对象分割模型和单帧注释进行初始化，进一步加速了优化过程。为了评估质量和速度，构建了Crello Animation数据集，包含高质量的动画图形模板，以及定制的基准度量来评估分解的质量。实验表明，该方法在质量/效率权衡方面显著优于同类分解基线。

#### 主要贡献：

1. 提出了一种简单而高效的基于优化的精灵分解方法，适用于动画图形。
2. 构建了Crello Animation数据集和基准指标，用于评估分解质量。
3. 实验证明了方法在质量/效率权衡方面的强大基准，并实现了显著更快的收敛，达到相同的分解质量。

#### 相关工作：

- **图像向量化和分解**：任务是将输入图像转换为可以渲染或绘制为视觉上与输入相同的目标参数化表示。
- **视频分解**：尝试将矢量视频分解为层，但不尝试参数化它们。

#### 方法概览：

1. **数据定义**：动画图形定义为一系列精灵，每个精灵由静态纹理图像和动画参数组成。
2. **问题形式化**：定义分解问题为找到与目标矢量视频视觉上一致的最佳参数集。
3. **解决策略**：
   - 引入图像先验模型，重新定义纹理优化为目标搜索模型参数和代码，以防止不希望的艺术效果。
   - 假设用户提供额外的辅助边界框注释，简化问题设置，实现高效初始化。
   - 使用预训练的视频对象分割模型识别良好的初始解决方案。
   - 使用简单的初始化流程和有效的优化器（如Adam）进行优化。

#### 结论与未来研究：

本文解决了动画图形中精灵的分解问题，通过引入一系列策略实现了高效分解，尤其是在动画图形上下文中。构建的新数据集和定制的评估指标展示了方法在质量与收敛时间之间的成功权衡。未来的研究可能考虑放松静态精灵假设，将变形和透明度作为时间函数表示，以支持更高级的视频编辑功能。
# Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03900)
# **标题**

《多语言语音理解（SLU）数据集：Speech-MASSIVE》

# **作者信息**

- **Lee Beomseok**  
  - University of Trento, Italy  
- **Calapodescu Ioan**  
  - NAVER LABS Europe, France  
- **Gaido Marco**, **Negri Matteo**, **Besacier Laurent**  
  - Fondazione Bruno Kessler, Italy  

# **论文标签**

- **多语言语音理解**
- **多模态数据集**
- **跨语言任务评估**
- **基础模型性能**
- **语音转写**
- **语言识别**
- **语音翻译**

# **研究核心目标与问题**

本文旨在解决多语言语音理解（SLU）数据集稀缺的问题，以及对多语言基础模型（如大型语言模型（LLMs）、语音编码器）进行全面评估的需求。研究通过引入一个包含12种不同语系的多语言语音数据集——Speech-MASSIVE，以填补这一空白。该数据集覆盖了文本对应部分的MASSIVE语料库，继承了MASSIVE中的意图预测和槽填充注释。研究的目标是通过提供一个多模态、多任务、多语言的数据集，评估基于链式架构和端到端架构的语音理解基线模型在零样本、有限样本和全量微调场景下的性能。

# **采用方法与技术**

研究采用了Whisper模型作为端到端（E2E）的语音理解模型的基础，该模型在避免中间文本表示的情况下直接解决问题。Whisper模型在与链式系统和其他语音编码器（如wav2vec2.0和HuBERT）的比较中表现出优越的性能。模型训练遵循序列到序列的方法，将预测扩展至包含转录文本、槽和意图。研究还提出了一种在不修改原始词汇表的情况下利用“|”和“_”作为任务分隔符的策略，以充分利用Whisper的分词器特性。在零样本模式下，研究使用了Whisper-large-v3模型，分别进行了英文和法文训练集的微调。

# **实验设计与主要发现**

实验设计涵盖了各种训练场景，包括零样本、有限样本和全量微调。实验结果显示，Speech-MASSIVE数据集不仅适用于语音理解任务，还能用于基准测试其他任务，如语音转写、语言识别和语音翻译。通过不同配置下的实验，研究团队提供了广泛的性能指标，包括准确度、精确匹配准确率、意图准确率、类型F1分数和值字符错误率（CER），从而为评估不同模型在多语言环境下的表现提供了详细的依据。

# **结论及对未来研究的意义**

Speech-MASSIVE数据集的发布为多语言语音理解领域的研究者提供了一个宝贵的资源，有助于促进跨语言的基础模型开发和评估。研究结果表明，Speech-MASSIVE不仅能够有效支持现有的语音理解任务，还能够作为其他语言处理任务的基准。此外，数据集、模型和代码的开源性质鼓励了社区内的合作与创新，为未来的多语言语音理解研究奠定了坚实的基础。

# **关键图表与数据**

- **准确匹配准确率表**（Table 5）
- **意图准确性表**（Table 6）
- **类型F1分数和值字符错误率表**（Table 8）

这些图表和数据点对于理解模型在不同语言和训练条件下的性能至关重要，为研究结论提供了量化支持。
# Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03588)
### **论文标题**
- 面对音乐：处理影视音频源分离中的歌唱声分离问题

### **作者信息**
- **Karn N. Watcharasupat**: Netflix Inc., 美国加州洛斯加托斯 95032（实习）；Georgia Institute of Technology, 美国亚特兰大 30332
- **Chih-Wei Wu**: Netflix Inc., 美国加州洛斯加托斯 95032
- **Iroro Orife**: Netflix Inc., 美国加州洛斯加托斯 95032

### **论文标签**
- 影视音频源分离 (CASS)
- 歌唱声分离
- 音频处理
- 机器学习
- 深度学习

### **研究核心目标与问题**
- 本研究针对影视音频源分离任务中常见的边缘案例——歌唱声的位置问题，提出了一种扩展方案。由于歌唱声在不同场景下可能属于对话 (DX) 或音乐 (MX) 茎干，因此需要一种更为灵活的方法来处理这一特殊音源。

### **采用方法与技术**
- 使用 Bandit 和 Banquet 模型扩展到四茎干问题，其中增加了歌唱声作为独立茎干。Bandit 模型为每个茎干配备了专用解码器，而 Banquet 模型则采用了基于查询的单一共享解码器架构。两种模型均使用了改进版的 Divide and Remaster 数据集进行训练，该数据集中的音乐茎干来自 MUSDB18-HQ 和 MoisesDB 数据集，以提供更纯净的声乐和乐器分离真值。

### **实验设计与主要发现**
- 实验通过在改进的数据集上训练两种模型并比较它们的表现来进行。结果显示，Banquet 模型在所有茎干上的性能都优于 Bandit 模型，特别是在歌唱声和对话茎干上表现出中等到较大的效应量。尽管参数量少于 Bandit 模型，Banquet 在分离效果上仍然表现得更好。

### **结论及对未来研究的意义**
- 本文展示了如何通过扩展 Bandit 和 Banquet 模型来处理歌唱声分离的问题。实验结果表明，基于查询的 Banquet 模型能够实现更好的特征对齐，这可能是其性能优于 Bandit 模型的原因之一。未来的研究可以进一步探索如何优化特征表示以增强模型的分离能力。

### **关键图表与数据**
- 表1展示了 Bandit 和 Banquet 模型在各茎干上的信号噪声比 (SNR) 和尺度不变 SNR (SI-SNR) 的中位数值，Banquet 模型在所有测试中均取得了更好的结果。
- 图2是每个茎干的 γi 值的归一化聚类图，显示了不同特征在各茎干中的激活情况，支持了 Banquet 模型在特征层面实现更好独立性的假设。
# Compact 3D Gaussian Splatting for Static and Dynamic Radiance Fields
[arxiv_pdf_url](https://arxiv.org/pdf/2408.03822)
这篇论文提出了一种名为“紧凑型3D高斯散射（Compact 3D Gaussian Splatting）”的方法，用于静态和动态辐射场的表示。该方法针对神经辐射场（Neural Radiance Fields, NeRFs）的一个关键挑战——计算瓶颈，通过减少高维空间中的点的数量来优化内存和存储效率，同时保持高质量的渲染、快速的训练速度以及实时渲染能力。具体改进包括：

1. **可学习掩码策略**：通过引入基于体积和透明度的可学习掩码策略，该方法能够识别并消除那些对整体渲染质量贡献较小的冗余高斯点。这种方法不仅减少了高斯点的数量，而且在整个训练过程中持续进行，有效降低了不必要的计算量和GPU内存使用。

2. **紧凑的属性表示**：对于几何属性（如尺度和旋转），提出了基于代码本的学习方法，利用残差向量化量化（Residual Vector Quantization, R-VQ）有效地压缩了参数，而不需要大量的计算复杂性和GPU内存。此外，对于视依赖颜色，使用网格基神经场替代直接存储高阶Spherical Harmonics系数，以减少存储需求。

3. **动态场景扩展**：为了适应动态场景，该方法扩展了时间相关性，同时考虑空间和时间上的冗余。通过空间-时间掩码策略，该方法能够有效去除动态场景中的冗余高斯点。此外，提出了空间-时间代码本和R-VQ来紧凑表示时间和几何属性。

4. **后处理技术**：通过简单的后处理技术，如量化、剪枝和哈夫曼编码，进一步减小了模型大小，同时保持了高性能。

5. **性能评估**：在多个真实世界和合成数据集上进行了实验，结果显示与原始3D散射（3DGS）相比，该方法在保持高质量重建的同时，实现了高达25倍的存储减少和超过12倍的压缩比。特别是在动态场景中，该方法展示了超过9倍的压缩比，同时保持了高表现。

总的来说，该工作提供了一个全面的框架，适用于静态和动态3D场景的高效表示，结合了高质量的渲染、快速的训练和实时渲染能力，为更广泛的采用和应用于需要高效高质量3D场景表示的领域铺平了道路。